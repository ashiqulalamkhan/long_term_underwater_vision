{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#CAMERA INTRINSICS FROM METASHAPE xml FILE\n",
    "def get_cam_intrinsics(root):\n",
    "    camera_intrinsics = []\n",
    "    y = []\n",
    "    for node in root.iter(\"calibration\"):\n",
    "        x = list(node.attrib.values())\n",
    "        if (x[1]==\"adjusted\"):\n",
    "            for node2 in node.iter():\n",
    "                camera_intrinsics.append(node2.text)\n",
    "                y.append(list(node2.attrib.values()))\n",
    "    camera_intrinsics = list(map(float,camera_intrinsics[2:]))\n",
    "    width, height = list(map(float,y[1]))\n",
    "    camera_intrinsics_dict = {\"width\":width,\n",
    "                              \"height\":height,\n",
    "                              \"f\":camera_intrinsics[0],\n",
    "                              \"cx\":camera_intrinsics[1],\n",
    "                              \"cy\":camera_intrinsics[2],\n",
    "                              \"b1\":camera_intrinsics[3],\n",
    "                              \"b2\":camera_intrinsics[4],\n",
    "                              \"k1\":camera_intrinsics[5],\n",
    "                              \"k2\":camera_intrinsics[6],\n",
    "                              \"k3\":camera_intrinsics[7],\n",
    "                              \"k4\":camera_intrinsics[8],\n",
    "                              \"p1\":camera_intrinsics[9],\n",
    "                              \"p2\":camera_intrinsics[10]}\n",
    "    return camera_intrinsics_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#CAMERA POSE PER IMAGE ID\n",
    "def get_cam_pose(root):\n",
    "    camera = []\n",
    "    for cam in root.iter(\"camera\"):\n",
    "        camera_id = int(list(cam.attrib.values())[0])\n",
    "        img_id = list(cam.attrib.values())[-1]\n",
    "        #print(camera_id, img_id)\n",
    "        for item in cam.iter(\"transform\"):\n",
    "            val = np.matrix(item.text)\n",
    "            transform_mat = np.reshape(val, (4,4))\n",
    "            #print(transform_mat)\n",
    "        for item in cam.iter(\"reference\"):\n",
    "            ref = item.attrib\n",
    "            #print(ref)\n",
    "        camera_dict = {\"image_id\" : img_id,\n",
    "                            \"transform_mat\" : transform_mat,\n",
    "                            \"reference\" : ref}\n",
    "        camera.append(camera_dict)\n",
    "    return camera"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "file = \"/home/turin/Desktop/lizard_dataset_curated/2014/camera_2014_local.xml\"\n",
    "file = \"/home/turin/Desktop/lizard_dataset_curated/2014/camera_2014.xml\"\n",
    "tree = ET.parse(file)\n",
    "root = tree.getroot()\n",
    "camera_intrinsics = get_cam_intrinsics(root)\n",
    "camera_pose = get_cam_pose(root)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'image_id': 'PR_20141102_074954_230_LC16.png',\n 'transform_mat': matrix([[-0.6513932 , -0.58034927, -0.48875518, 39.75346353],\n         [-0.74991552,  0.59040702,  0.29840621, 73.73233388],\n         [ 0.11538466,  0.56090487, -0.81980004,  6.61055763],\n         [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n 'reference': {'x': '145.44389459999999',\n  'y': '-14.68753156',\n  'z': '1.4386863999999999',\n  'yaw': '38.636250250000003',\n  'pitch': '-7.3203773539999997',\n  'roll': '12.039603720000001',\n  'enabled': 'true'}}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_pose[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'image_id': 'PR_20141102_074954_230_LC16.png',\n 'transform_mat': matrix([[-0.6513932 , -0.58034927, -0.48875518, 39.75346353],\n         [-0.74991552,  0.59040702,  0.29840621, 73.73233388],\n         [ 0.11538466,  0.56090487, -0.81980004,  6.61055763],\n         [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n 'reference': {'x': '145.44389459999999',\n  'y': '-14.68753156',\n  'z': '1.4386863999999999',\n  'yaw': '38.636250250000003',\n  'pitch': '-7.3203773539999997',\n  'roll': '12.039603720000001',\n  'enabled': 'true'}}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_pose[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
